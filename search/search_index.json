{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bayesian Evolutionary Layered Learning Architectures (BELLA) is a BEAST 2 package that brings unsupervised Bayesian neural networks to phylodynamic inference, letting you map rich predictor sets (traits, time series, environmental covariates) to key parameters such as speciation, extinction, transmission, and migration rates \u2014 all learned jointly with the phylogeny via MCMC. \ud83e\udded Overview BELLA integrates phylogenetic data with predictor covariates\u2014such as traits, environmental time series, or mobility patterns\u2014and prior knowledge on phylodynamic parameters. Importantly, this is formulated as an unsupervised learning problem: no evolutionary or epidemiological rates are observed or used as training targets. Instead, BELLA employs a Bayesian neural network to flexibly learn how predictors relate to key parameters\u2014such as speciation, extinction, transmission, or migration rates\u2014directly through the phylogenetic likelihood. This allows the model to capture complex, nonlinear dependencies that go beyond traditional generalized linear models (GLMs) and skyline models. All parameters, including the neural network weights, are estimated jointly within a Markov chain Monte Carlo framework. The resulting posterior distributions enable both inference of population dynamics and interpretation of predictor effects using explainable AI tools. \u2728 Features \ud83e\udde0\ud83d\udcc8 Nonlinear, highly flexible mappings that model smooth, high-dimensional relationships between predictors and phylodynamic parameters, generalizing and extending GLMs and skyline models without restrictive linearity or piecewise-constant assumptions. \ud83e\uddec\ud83e\udd16 Unsupervised Bayesian neural networks whose weights are inferred jointly with the phylogeny and evolutionary parameters by conditioning directly on the sequence likelihood\u2014eliminating the need for external response variables or labeled training data. \u2696\ufe0f\ud83d\udd12 Built-in regularization via weight priors that penalize overly complex functions, reducing overfitting while propagating uncertainty into phylodynamic estimates. \ud83d\udd0d\ud83e\udde9 Explainable AI tooling using partial dependence plots and SHAP-style attribution scores to quantify and visualize predictor effects on inferred phylodynamic parameters. \u2699\ufe0f\ud83d\udc12\ud83e\udda0 Deep BEAST 2 integration enabling end-to-end Bayesian inference for epidemiological and macroevolutionary workflows within existing BEAST 2 pipelines. \u2699\ufe0f Installation BELLA is available as a package for BEAST 2.7+ . You can install it via BEAUti as follows: Open BEAUti. Go to File \u2192 Manage Packages . Click Package repositories . Add URL and enter: https://raw.githubusercontent.com/gabriele-marino/BELLA/main/package.xml . Click OK to add the repository. Close the Package Repositories window. Return to the Package Manager window, scroll down to find BELLA , select it, and click Install/Upgrade. You're now ready to use BELLA! \ud83d\ude80 Getting started We provide several well-documented example configuration files in the BELLA examples directory, covering a range of use cases. See the examples README to get started! If you are new to BEAST 2, consider exploring the tutorials to familiarize yourself with BEAST XML configuration files and MCMC analyses. If you\u2019ve already run your analyses and want to postprocess the results, check out the BELLA-companion Python package, which includes helpful plotting tools like the ones shown above. \u2757\ufe0f If you don't find what you're looking for, please reach out \u2014I\u2019m always happy to help! \ud83d\udcd1 Citing BELLA If you use BELLA in your research, please cite the following: COMING SOON \ud83d\udceb Contact For questions, bug reports, or feature requests, please, consider opening an issue on GitHub , or contact me directly . For help with configuration files, don\u2019t hesitate to reach out \u2014 I\u2019m happy to assist!","title":"Home"},{"location":"#overview","text":"BELLA integrates phylogenetic data with predictor covariates\u2014such as traits, environmental time series, or mobility patterns\u2014and prior knowledge on phylodynamic parameters. Importantly, this is formulated as an unsupervised learning problem: no evolutionary or epidemiological rates are observed or used as training targets. Instead, BELLA employs a Bayesian neural network to flexibly learn how predictors relate to key parameters\u2014such as speciation, extinction, transmission, or migration rates\u2014directly through the phylogenetic likelihood. This allows the model to capture complex, nonlinear dependencies that go beyond traditional generalized linear models (GLMs) and skyline models. All parameters, including the neural network weights, are estimated jointly within a Markov chain Monte Carlo framework. The resulting posterior distributions enable both inference of population dynamics and interpretation of predictor effects using explainable AI tools.","title":"\ud83e\udded Overview"},{"location":"#features","text":"\ud83e\udde0\ud83d\udcc8 Nonlinear, highly flexible mappings that model smooth, high-dimensional relationships between predictors and phylodynamic parameters, generalizing and extending GLMs and skyline models without restrictive linearity or piecewise-constant assumptions. \ud83e\uddec\ud83e\udd16 Unsupervised Bayesian neural networks whose weights are inferred jointly with the phylogeny and evolutionary parameters by conditioning directly on the sequence likelihood\u2014eliminating the need for external response variables or labeled training data. \u2696\ufe0f\ud83d\udd12 Built-in regularization via weight priors that penalize overly complex functions, reducing overfitting while propagating uncertainty into phylodynamic estimates. \ud83d\udd0d\ud83e\udde9 Explainable AI tooling using partial dependence plots and SHAP-style attribution scores to quantify and visualize predictor effects on inferred phylodynamic parameters. \u2699\ufe0f\ud83d\udc12\ud83e\udda0 Deep BEAST 2 integration enabling end-to-end Bayesian inference for epidemiological and macroevolutionary workflows within existing BEAST 2 pipelines.","title":"\u2728 Features"},{"location":"#installation","text":"BELLA is available as a package for BEAST 2.7+ . You can install it via BEAUti as follows: Open BEAUti. Go to File \u2192 Manage Packages . Click Package repositories . Add URL and enter: https://raw.githubusercontent.com/gabriele-marino/BELLA/main/package.xml . Click OK to add the repository. Close the Package Repositories window. Return to the Package Manager window, scroll down to find BELLA , select it, and click Install/Upgrade. You're now ready to use BELLA!","title":"\u2699\ufe0f Installation"},{"location":"#getting-started","text":"We provide several well-documented example configuration files in the BELLA examples directory, covering a range of use cases. See the examples README to get started! If you are new to BEAST 2, consider exploring the tutorials to familiarize yourself with BEAST XML configuration files and MCMC analyses. If you\u2019ve already run your analyses and want to postprocess the results, check out the BELLA-companion Python package, which includes helpful plotting tools like the ones shown above. \u2757\ufe0f If you don't find what you're looking for, please reach out \u2014I\u2019m always happy to help!","title":"\ud83d\ude80 Getting started"},{"location":"#citing-bella","text":"If you use BELLA in your research, please cite the following: COMING SOON","title":"\ud83d\udcd1 Citing BELLA"},{"location":"#contact","text":"For questions, bug reports, or feature requests, please, consider opening an issue on GitHub , or contact me directly . For help with configuration files, don\u2019t hesitate to reach out \u2014 I\u2019m happy to assist!","title":"\ud83d\udceb Contact"},{"location":"components/","text":"Components This section describes the main BELLA components you can use in your BEAST XML files. The core component is the BayesMLP , which implements a Bayesian multilayer perceptron (MLP) to map predictor variables to phylodynamic parameters. Additionally, BELLA includes several ActivationFunction s that can be used within the MLP. These components rely on standard BEAST interfaces such as CalculationNode , RealParameter , Function , and Loggable , and are designed to be flexible and integrate seamlessly with BEAST 2's MCMC framework. bella.BayesMLP BayesMLP is the main BELLA component you reference in a BEAST XML. It extends CalculationNode and implements Function and Loggable , which makes it: A value-producing node ( Function ): it outputs a vector of predicted rates. A recalculating node ( CalculationNode ): it recomputes only when needed. A loggable node ( Loggable ): it can print its weights to the BEAST log. A BayesMLP represents a fully connected feedforward neural network (multilayer perceptron, MLP) with arbitrary hidden layers, used to map predictor variables to phylodynamic parameters. It has the following BEAST XML attributes: predictor (required): list of RealParameter objects. Each parameter is a vector of predictor values. All predictors must have the same length, which defines the number of observations (e.g., time bins), and corresponds to the size of the output of the network. weights (required): list of RealParameter objects, one per layer connection. Each is a flattened weight matrix (row-major) for a single layer. The size of each weight matrix is determined internally by the number of neurons in the source and target layers, and is equal to \\((\\text{n_source} + 1) \\times \\text{n_target}\\) (the +1 accounts for the bias term). nodes (optional): number of neurons in each hidden layer. For example, nodes=\"16 8\" means two hidden layers: 16 and 8 neurons. Default is an empty list, corresponding to no hidden layers. hiddenActivation (optional): activation function for hidden layers. Default: ReLU. outputActivation (optional): activation function for the output layer. Default: Sigmoid. normalize (optional): Whether to apply min\u2013max normalization to predictor values, scaling them to the range \\([0, 1]\\) before they are passed to the network. Default: true . When a BayesMLP object is initialized, the class builds the full layer sizes, using the number of predictors as the size of the input layer and 1 as the size of the output layer. So if you pass nodes=\"16 8\" and you have 3 predictors, the internal layer sizes are: \\([3, 16, 8, 1]\\) . That implies 3 weight matrices: Layer 1: \\((3 + 1) \\times 16\\) Layer 2: \\((16 + 1) \\times 8\\) Layer 3: \\((8 + 1) \\times 1\\) . Because of this, the number of weights parameters must equal the number of hidden layers + 1. If not, an error is raised during initialization. Predictor values are managed within the class as a matrix of size \\((\\text{num_observations} \\times \\text{num_predictors})\\) . Each row corresponds to one observation (e.g., a time bin), and each column to one predictor variable. When performing a forward pass, the entire matrix is processed at once, yielding an output vector of size \\((\\text{num_observations} \\times 1)\\) . Thus, each observation gets its own predicted rate. BayesMLP implements the Loggable interface, which makes it possible to log the network weights during MCMC. When you add a BayesMLP to the BEAST log, it will output one column per weight in the network, using the following format: <id>W.Layer<X>[<i>][<j>] , where: <id> is the BEAST object ID of the BayesMLP instance. <X> is the layer index (1-based). <i> is the input neuron index (including bias term, so \\(i=0\\) is bias). <j> is the output neuron index. bella.activations Activation functions are used within the BayesMLP to introduce nonlinearity. BELLA provides several built-in activation functions that you can specify in your BEAST XML configuration: bella.activations.Identity : Identity activation function. Implements \\(f(z) = z\\) . bella.activations.ReLU : Rectified Linear Unit (ReLU) activation function. Implements \\(f(z) = \\max(0, z)\\) . bella.activations.Tanh : Hyperbolic tangent activation function. Implements \\(f(z) = \\tanh(z)\\) . bella.activations.SoftPlus : SoftPlus activation function. Implements \\(f(z) = \\log(1 + \\exp(z))\\) , with numerical stability. bella.activations.Sigmoid : Sigmoid activation function with customizable parameters. Implements a bounded logistic function defined by: $$ f(z) = \\text{lower} + \\frac{\\text{upper} - \\text{lower}}{1 + \\exp(-\\text{shape} * (z - \\text{midpoint}))} $$ where \\(\\text{lower}\\) , \\(\\text{upper}\\) , \\(\\text{shape}\\) , and \\(\\text{midpoint}\\) are parameters you can set in the XML. The output activation function is a useful way to enforce particular behaviors on the network\u2019s output, such as bounding rates within a specific range using the sigmoid function. The hidden activation function is typically set to ReLU because its non-saturating linear regime avoids compression of activity and supports a wide dynamic range.","title":"Components"},{"location":"components/#components","text":"This section describes the main BELLA components you can use in your BEAST XML files. The core component is the BayesMLP , which implements a Bayesian multilayer perceptron (MLP) to map predictor variables to phylodynamic parameters. Additionally, BELLA includes several ActivationFunction s that can be used within the MLP. These components rely on standard BEAST interfaces such as CalculationNode , RealParameter , Function , and Loggable , and are designed to be flexible and integrate seamlessly with BEAST 2's MCMC framework.","title":"Components"},{"location":"components/#bellabayesmlp","text":"BayesMLP is the main BELLA component you reference in a BEAST XML. It extends CalculationNode and implements Function and Loggable , which makes it: A value-producing node ( Function ): it outputs a vector of predicted rates. A recalculating node ( CalculationNode ): it recomputes only when needed. A loggable node ( Loggable ): it can print its weights to the BEAST log. A BayesMLP represents a fully connected feedforward neural network (multilayer perceptron, MLP) with arbitrary hidden layers, used to map predictor variables to phylodynamic parameters. It has the following BEAST XML attributes: predictor (required): list of RealParameter objects. Each parameter is a vector of predictor values. All predictors must have the same length, which defines the number of observations (e.g., time bins), and corresponds to the size of the output of the network. weights (required): list of RealParameter objects, one per layer connection. Each is a flattened weight matrix (row-major) for a single layer. The size of each weight matrix is determined internally by the number of neurons in the source and target layers, and is equal to \\((\\text{n_source} + 1) \\times \\text{n_target}\\) (the +1 accounts for the bias term). nodes (optional): number of neurons in each hidden layer. For example, nodes=\"16 8\" means two hidden layers: 16 and 8 neurons. Default is an empty list, corresponding to no hidden layers. hiddenActivation (optional): activation function for hidden layers. Default: ReLU. outputActivation (optional): activation function for the output layer. Default: Sigmoid. normalize (optional): Whether to apply min\u2013max normalization to predictor values, scaling them to the range \\([0, 1]\\) before they are passed to the network. Default: true . When a BayesMLP object is initialized, the class builds the full layer sizes, using the number of predictors as the size of the input layer and 1 as the size of the output layer. So if you pass nodes=\"16 8\" and you have 3 predictors, the internal layer sizes are: \\([3, 16, 8, 1]\\) . That implies 3 weight matrices: Layer 1: \\((3 + 1) \\times 16\\) Layer 2: \\((16 + 1) \\times 8\\) Layer 3: \\((8 + 1) \\times 1\\) . Because of this, the number of weights parameters must equal the number of hidden layers + 1. If not, an error is raised during initialization. Predictor values are managed within the class as a matrix of size \\((\\text{num_observations} \\times \\text{num_predictors})\\) . Each row corresponds to one observation (e.g., a time bin), and each column to one predictor variable. When performing a forward pass, the entire matrix is processed at once, yielding an output vector of size \\((\\text{num_observations} \\times 1)\\) . Thus, each observation gets its own predicted rate. BayesMLP implements the Loggable interface, which makes it possible to log the network weights during MCMC. When you add a BayesMLP to the BEAST log, it will output one column per weight in the network, using the following format: <id>W.Layer<X>[<i>][<j>] , where: <id> is the BEAST object ID of the BayesMLP instance. <X> is the layer index (1-based). <i> is the input neuron index (including bias term, so \\(i=0\\) is bias). <j> is the output neuron index.","title":"bella.BayesMLP"},{"location":"components/#bellaactivations","text":"Activation functions are used within the BayesMLP to introduce nonlinearity. BELLA provides several built-in activation functions that you can specify in your BEAST XML configuration: bella.activations.Identity : Identity activation function. Implements \\(f(z) = z\\) . bella.activations.ReLU : Rectified Linear Unit (ReLU) activation function. Implements \\(f(z) = \\max(0, z)\\) . bella.activations.Tanh : Hyperbolic tangent activation function. Implements \\(f(z) = \\tanh(z)\\) . bella.activations.SoftPlus : SoftPlus activation function. Implements \\(f(z) = \\log(1 + \\exp(z))\\) , with numerical stability. bella.activations.Sigmoid : Sigmoid activation function with customizable parameters. Implements a bounded logistic function defined by: $$ f(z) = \\text{lower} + \\frac{\\text{upper} - \\text{lower}}{1 + \\exp(-\\text{shape} * (z - \\text{midpoint}))} $$ where \\(\\text{lower}\\) , \\(\\text{upper}\\) , \\(\\text{shape}\\) , and \\(\\text{midpoint}\\) are parameters you can set in the XML. The output activation function is a useful way to enforce particular behaviors on the network\u2019s output, such as bounding rates within a specific range using the sigmoid function. The hidden activation function is typically set to ReLU because its non-saturating linear regime avoids compression of activity and supports a wide dynamic range.","title":"bella.activations"},{"location":"highlights/","text":"\ud83d\udca1 Highlights from the BELLA Paper \ud83d\udcd1\ud83d\udce2 The full BELLA manuscript is available on COMING SOON , and all experiments can be reproduced using the companion code . \ud83d\udcc8 Capturing nonlinear dynamics with BELLA We tested BELLA on a simulation scenario involving the prediction of 20 migration rates across 5 populations under nonlinear predictor\u2013parameter relationships. BELLA accurately captures these nonlinear patterns and outperforms both a generalized linear model (GLM) and predictor-agnostic baselines, which struggle when dynamics are nonlinear or only a few independent parameters drive variation. \ud83d\udd0d Interpreting the BELLA model We assessed our interpretation framework using a macroevolutionary simulation in which speciation ( \\(\\lambda\\) , top row) and extinction ( \\(\\mu\\) , bottom row) rates varied through time and among four groups of species as a function of a binary trait evolving along the phylogeny. The analysis included four predictors: time and a relevant binary trait (red), as well as an unrelated time series and an additional binary trait with no effect on diversification (gray). Partial dependence plots (PDPs) recovered the marginal effects of the relevant predictors, capturing the expected temporal decrease in speciation and increase in extinction rates, as well as trait-dependent shifts in both parameters, while indicating negligible influence of the irrelevant predictors. These patterns were corroborated by SHAP feature importance analyses, which identified time and the relevant trait as the dominant contributors to model output. Median predicted rates through time across species groups closely matched the simulated phylodynamic regimes, confirming that BELLA accurately identifies relevant drivers of diversification while remaining robust to uninformative predictors. \ud83d\udc12 Leveraging BELLA in macroevolutionary analyses We used BELLA to model the macroevolutionary history of New World monkey phylogenies, estimating diversification rates as functions of time and body mass. PDPs revealed a strong non-additive interaction between temporal and trait-dependent effects on diversification. Specifically, small-bodied lineages showed a steady increase in diversification through time, whereas larger-bodied lineages experienced a pronounced mid-Miocene decline followed by a rebound toward the present. This complex interaction would have been difficult to detect using alternative phylodynamic models. \ud83e\udda0 Leveraging BELLA in epidemiological analyses We applied BELLA to estimate SARS-CoV-2 migration rates across countries during the early spread of the virus in China and Europe. Migration rates were modeled as a function of the number of flights between countries, normalized by the population size of the source country. We reconstructed the geographic spread of the outbreak, identifying Italy as the most probable location of the most recent common ancestor of the European clade, with Italy inferred as the principal exporter of viral lineages and Germany as the main importer during this phase of the pandemic. We further examined how BELLA and a GLM link migration rates to the normalized number of flights using PDPs. BELLA recovered a nonlinear relationship that flattens at high predictor values, indicating a saturation effect that cannot be accommodated by the GLM\u2019s linear functional form.","title":"Highlights from the paper"},{"location":"highlights/#highlights-from-the-bella-paper","text":"\ud83d\udcd1\ud83d\udce2 The full BELLA manuscript is available on COMING SOON , and all experiments can be reproduced using the companion code .","title":"\ud83d\udca1 Highlights from the BELLA Paper"},{"location":"highlights/#capturing-nonlinear-dynamics-with-bella","text":"We tested BELLA on a simulation scenario involving the prediction of 20 migration rates across 5 populations under nonlinear predictor\u2013parameter relationships. BELLA accurately captures these nonlinear patterns and outperforms both a generalized linear model (GLM) and predictor-agnostic baselines, which struggle when dynamics are nonlinear or only a few independent parameters drive variation.","title":"\ud83d\udcc8 Capturing nonlinear dynamics with BELLA"},{"location":"highlights/#interpreting-the-bella-model","text":"We assessed our interpretation framework using a macroevolutionary simulation in which speciation ( \\(\\lambda\\) , top row) and extinction ( \\(\\mu\\) , bottom row) rates varied through time and among four groups of species as a function of a binary trait evolving along the phylogeny. The analysis included four predictors: time and a relevant binary trait (red), as well as an unrelated time series and an additional binary trait with no effect on diversification (gray). Partial dependence plots (PDPs) recovered the marginal effects of the relevant predictors, capturing the expected temporal decrease in speciation and increase in extinction rates, as well as trait-dependent shifts in both parameters, while indicating negligible influence of the irrelevant predictors. These patterns were corroborated by SHAP feature importance analyses, which identified time and the relevant trait as the dominant contributors to model output. Median predicted rates through time across species groups closely matched the simulated phylodynamic regimes, confirming that BELLA accurately identifies relevant drivers of diversification while remaining robust to uninformative predictors.","title":"\ud83d\udd0d Interpreting the BELLA model"},{"location":"highlights/#leveraging-bella-in-macroevolutionary-analyses","text":"We used BELLA to model the macroevolutionary history of New World monkey phylogenies, estimating diversification rates as functions of time and body mass. PDPs revealed a strong non-additive interaction between temporal and trait-dependent effects on diversification. Specifically, small-bodied lineages showed a steady increase in diversification through time, whereas larger-bodied lineages experienced a pronounced mid-Miocene decline followed by a rebound toward the present. This complex interaction would have been difficult to detect using alternative phylodynamic models.","title":"\ud83d\udc12 Leveraging BELLA in macroevolutionary analyses"},{"location":"highlights/#leveraging-bella-in-epidemiological-analyses","text":"We applied BELLA to estimate SARS-CoV-2 migration rates across countries during the early spread of the virus in China and Europe. Migration rates were modeled as a function of the number of flights between countries, normalized by the population size of the source country. We reconstructed the geographic spread of the outbreak, identifying Italy as the most probable location of the most recent common ancestor of the European clade, with Italy inferred as the principal exporter of viral lineages and Germany as the main importer during this phase of the pandemic. We further examined how BELLA and a GLM link migration rates to the normalized number of flights using PDPs. BELLA recovered a nonlinear relationship that flattens at high predictor values, indicating a saturation effect that cannot be accommodated by the GLM\u2019s linear functional form.","title":"\ud83e\udda0 Leveraging BELLA in epidemiological analyses"},{"location":"tutorials/","text":"Tutorials overview Welcome to the BELLA tutorials \u2705. This section is split into: A general overview of BEAST and BELLA. One tutorial per example in examples/ . If you are new to BEAST, start here before jumping into the example pages. BEAST in one minute BEAST (Bayesian Evolutionary Analysis by Sampling Trees) runs MCMC to estimate phylogenies and model parameters. A BEAST analysis is defined by an XML configuration file that declares: data (trees, alignments, predictors) model components (priors, likelihoods, parameterizations) MCMC settings (operators, logging, chain length) Think of the XML as a model graph : nodes compute values, and BEAST samples the parameters that feed those nodes. Where BELLA fits BELLA provides a Bayesian neural network component that lives inside the BEAST model graph. In practice: You declare predictors (trait vectors or time series). BELLA ( bella.BayesMLP ) maps predictors -> rates. Those rates feed a phylodynamic model (birth-death, migration, etc.). This lets BEAST estimate network weights and evolutionary parameters jointly . BELLA behaves like any other BEAST component: it is a CalculationNode (recomputes when its inputs change), a Function (outputs a vector of values), and a Loggable (it can write to BEAST logs). How a BELLA XML is structured Below is the mental model for a BELLA-driven BEAST analysis: Data + predictors + priors v BEAST XML v MCMC v Posterior logs 1) XML skeleton Every BEAST XML starts with a <beast> tag and a namespace that includes BELLA and any extra packages you need. 2) Data inputs You typically provide: a tree (often Newick) one or more predictor vectors (CSV or direct values) 3) State nodes (parameters to estimate) In BEAST, state nodes are parameters sampled by MCMC. For BELLA, these are usually the network weights . Other parameters (like sampling rates, clock rates, or population sizes) can also be sampled. Example: <state id=\"state\"> <plate var=\"n\" range=\"$(layersRange)\"> <stateNode spec=\"RealParameter\" id=\"birthRateW$(n)\" value=\"0\"/> <stateNode spec=\"RealParameter\" id=\"deathRateW$(n)\" value=\"0\"/> </plate> <stateNode spec=\"RealParameter\" id=\"samplingRate\" value=\"$(samplingRateInit)\"/> </state> How to think about it: layersRange expands one state node per layer connection . BELLA expects one weight parameter per connection (hidden layers + 1). The weight parameters are flattened vectors; BELLA reshapes them internally. 4) BELLA wiring (predictors -> rates) A BELLA MLP is defined in XML like this: <skylineValues id=\"birthRate\" spec=\"bella.BayesMLP\" nodes=\"$(nodes)\"> <predictor spec=\"RealParameterFromXSV\" fileName=\"$(birthRatePredictorFile)\"/> <plate var=\"n\" range=\"$(layersRange)\"> <weights idref=\"birthRateW$(n)\"/> </plate> <outputActivation spec=\"bella.activations.Sigmoid\" lower=\"$(birthRateLower)\" upper=\"$(birthRateUpper)\"/> </skylineValues> Key points: nodes defines hidden layers only. BELLA adds input and output layers automatically. The predictor list becomes a matrix. Each row is an observation (time bin), each column is a predictor. Use outputActivation to constrain the output range (Sigmoid is a common choice). If normalize=true (default), BELLA min-max normalizes predictor vectors to [0, 1] . 5) Time bins and skyline vectors BELLA often predicts skyline vectors , where each element is a rate for a time bin. If your XML contains: changeTimes = \"t1 t2 ...\" then the number of skyline values is: length(changeTimes) + 1 So every predictor vector must have that exact length. 6) Activation functions (hidden + output layers) BELLA supports multiple activation functions. You configure them in XML with hiddenActivation and outputActivation : <skylineValues id=\"birthRate\" spec=\"bella.BayesMLP\" nodes=\"$(nodes)\"> <predictor spec=\"RealParameterFromXSV\" fileName=\"$(birthRatePredictorFile)\"/> <hiddenActivation spec=\"bella.activations.ReLU\"/> <outputActivation spec=\"bella.activations.Sigmoid\" lower=\"$(birthRateLower)\" upper=\"$(birthRateUpper)\"/> ... </skylineValues> Available activations: ReLU : max(0, z) (default for hidden layers) Tanh : tanh(z) SoftPlus : log(1 + exp(z)) with a stable implementation Identity : z (no nonlinearity) Sigmoid : bounded logistic with parameters: lower and upper to clamp the output range shape (steepness) and midpoint (center) Practical guidance: Use Sigmoid for outputs that must stay within bounds (rates, probabilities). Use ReLU or Tanh for hidden layers to allow nonlinear mappings. If you want linear outputs, set outputActivation to Identity . 7) Likelihood and priors In BEAST, the posterior is a product of likelihood and prior terms: <distribution id=\"posterior\" spec=\"CompoundDistribution\"> <distribution id=\"likelihood\" spec=\"CompoundDistribution\"> <!-- model likelihood here --> </distribution> <distribution id=\"prior\" spec=\"CompoundDistribution\"> <!-- priors here --> </distribution> </distribution> BELLA weights are just parameters, so you place priors on them like any other RealParameter: <Normal id=\"weightsPrior\" mean=\"0\" sigma=\"1\"/> <plate var=\"n\" range=\"$(layersRange)\"> <distribution spec=\"Prior\" x=\"@birthRateW$(n)\" distr=\"@weightsPrior\"/> <distribution spec=\"Prior\" x=\"@deathRateW$(n)\" distr=\"@weightsPrior\"/> </plate> 8) Operators (how MCMC moves) Operators propose new parameter values so MCMC can explore the posterior. BELLA examples use Bactrian random walks on weights: <plate var=\"n\" range=\"$(layersRange)\"> <operator spec=\"BactrianRandomWalkOperator\" parameter=\"@birthRateW$(n)\" weight=\"30.0\"/> <operator spec=\"BactrianRandomWalkOperator\" parameter=\"@deathRateW$(n)\" weight=\"30.0\"/> </plate> Use higher weights for parameters that need more frequent updates. Tune operator weights and step sizes if mixing is poor. 9) Logging (including BELLA internals) Logging controls what you see in output files. You can log: posterior, likelihood, prior skyline rates BELLA outputs BELLA network weights Example logger: <logger spec=\"Logger\" fileName=\"FBD.log\" logEvery=\"$(logEvery)\" model=\"@posterior\"> <log idref=\"posterior\"/> <log idref=\"prior\"/> <log idref=\"likelihood\"/> <log idref=\"birthRateSP\"/> <log idref=\"deathRateSP\"/> <log idref=\"birthRate\"/> <log idref=\"deathRate\"/> </logger> How BELLA logs its weights: bella.BayesMLP implements Loggable . On init, it prints headers like W.LayerX[i][j] for every weight matrix entry. X is the layer index (1-based). i is the input neuron index (including the bias row as index 0). j is the output neuron index. During logging, it prints every weight value in order. So if you add <log idref=\"birthRate\"/> and <log idref=\"deathRate\"/> , you will get the full network weights per MCMC sample in your log file. 10) JSON + -DF substitutions BELLA examples use a data.json file that fills placeholders like $(treeFile) and $(nodes) at runtime. Run with: beast -DF path/to/data.json path/to/config.xml This is the easiest way to tweak a BELLA configuration without editing the XML directly. Next, choose a specific tutorial from the sidebar for a full, runnable example \ud83d\ude80.","title":"Overview"},{"location":"tutorials/#tutorials-overview","text":"Welcome to the BELLA tutorials \u2705. This section is split into: A general overview of BEAST and BELLA. One tutorial per example in examples/ . If you are new to BEAST, start here before jumping into the example pages.","title":"Tutorials overview"},{"location":"tutorials/#beast-in-one-minute","text":"BEAST (Bayesian Evolutionary Analysis by Sampling Trees) runs MCMC to estimate phylogenies and model parameters. A BEAST analysis is defined by an XML configuration file that declares: data (trees, alignments, predictors) model components (priors, likelihoods, parameterizations) MCMC settings (operators, logging, chain length) Think of the XML as a model graph : nodes compute values, and BEAST samples the parameters that feed those nodes.","title":"BEAST in one minute"},{"location":"tutorials/#where-bella-fits","text":"BELLA provides a Bayesian neural network component that lives inside the BEAST model graph. In practice: You declare predictors (trait vectors or time series). BELLA ( bella.BayesMLP ) maps predictors -> rates. Those rates feed a phylodynamic model (birth-death, migration, etc.). This lets BEAST estimate network weights and evolutionary parameters jointly . BELLA behaves like any other BEAST component: it is a CalculationNode (recomputes when its inputs change), a Function (outputs a vector of values), and a Loggable (it can write to BEAST logs).","title":"Where BELLA fits"},{"location":"tutorials/#how-a-bella-xml-is-structured","text":"Below is the mental model for a BELLA-driven BEAST analysis: Data + predictors + priors v BEAST XML v MCMC v Posterior logs","title":"How a BELLA XML is structured"},{"location":"tutorials/#1-xml-skeleton","text":"Every BEAST XML starts with a <beast> tag and a namespace that includes BELLA and any extra packages you need.","title":"1) XML skeleton"},{"location":"tutorials/#2-data-inputs","text":"You typically provide: a tree (often Newick) one or more predictor vectors (CSV or direct values)","title":"2) Data inputs"},{"location":"tutorials/#3-state-nodes-parameters-to-estimate","text":"In BEAST, state nodes are parameters sampled by MCMC. For BELLA, these are usually the network weights . Other parameters (like sampling rates, clock rates, or population sizes) can also be sampled. Example: <state id=\"state\"> <plate var=\"n\" range=\"$(layersRange)\"> <stateNode spec=\"RealParameter\" id=\"birthRateW$(n)\" value=\"0\"/> <stateNode spec=\"RealParameter\" id=\"deathRateW$(n)\" value=\"0\"/> </plate> <stateNode spec=\"RealParameter\" id=\"samplingRate\" value=\"$(samplingRateInit)\"/> </state> How to think about it: layersRange expands one state node per layer connection . BELLA expects one weight parameter per connection (hidden layers + 1). The weight parameters are flattened vectors; BELLA reshapes them internally.","title":"3) State nodes (parameters to estimate)"},{"location":"tutorials/#4-bella-wiring-predictors-rates","text":"A BELLA MLP is defined in XML like this: <skylineValues id=\"birthRate\" spec=\"bella.BayesMLP\" nodes=\"$(nodes)\"> <predictor spec=\"RealParameterFromXSV\" fileName=\"$(birthRatePredictorFile)\"/> <plate var=\"n\" range=\"$(layersRange)\"> <weights idref=\"birthRateW$(n)\"/> </plate> <outputActivation spec=\"bella.activations.Sigmoid\" lower=\"$(birthRateLower)\" upper=\"$(birthRateUpper)\"/> </skylineValues> Key points: nodes defines hidden layers only. BELLA adds input and output layers automatically. The predictor list becomes a matrix. Each row is an observation (time bin), each column is a predictor. Use outputActivation to constrain the output range (Sigmoid is a common choice). If normalize=true (default), BELLA min-max normalizes predictor vectors to [0, 1] .","title":"4) BELLA wiring (predictors -&gt; rates)"},{"location":"tutorials/#5-time-bins-and-skyline-vectors","text":"BELLA often predicts skyline vectors , where each element is a rate for a time bin. If your XML contains: changeTimes = \"t1 t2 ...\" then the number of skyline values is: length(changeTimes) + 1 So every predictor vector must have that exact length.","title":"5) Time bins and skyline vectors"},{"location":"tutorials/#6-activation-functions-hidden-output-layers","text":"BELLA supports multiple activation functions. You configure them in XML with hiddenActivation and outputActivation : <skylineValues id=\"birthRate\" spec=\"bella.BayesMLP\" nodes=\"$(nodes)\"> <predictor spec=\"RealParameterFromXSV\" fileName=\"$(birthRatePredictorFile)\"/> <hiddenActivation spec=\"bella.activations.ReLU\"/> <outputActivation spec=\"bella.activations.Sigmoid\" lower=\"$(birthRateLower)\" upper=\"$(birthRateUpper)\"/> ... </skylineValues> Available activations: ReLU : max(0, z) (default for hidden layers) Tanh : tanh(z) SoftPlus : log(1 + exp(z)) with a stable implementation Identity : z (no nonlinearity) Sigmoid : bounded logistic with parameters: lower and upper to clamp the output range shape (steepness) and midpoint (center) Practical guidance: Use Sigmoid for outputs that must stay within bounds (rates, probabilities). Use ReLU or Tanh for hidden layers to allow nonlinear mappings. If you want linear outputs, set outputActivation to Identity .","title":"6) Activation functions (hidden + output layers)"},{"location":"tutorials/#7-likelihood-and-priors","text":"In BEAST, the posterior is a product of likelihood and prior terms: <distribution id=\"posterior\" spec=\"CompoundDistribution\"> <distribution id=\"likelihood\" spec=\"CompoundDistribution\"> <!-- model likelihood here --> </distribution> <distribution id=\"prior\" spec=\"CompoundDistribution\"> <!-- priors here --> </distribution> </distribution> BELLA weights are just parameters, so you place priors on them like any other RealParameter: <Normal id=\"weightsPrior\" mean=\"0\" sigma=\"1\"/> <plate var=\"n\" range=\"$(layersRange)\"> <distribution spec=\"Prior\" x=\"@birthRateW$(n)\" distr=\"@weightsPrior\"/> <distribution spec=\"Prior\" x=\"@deathRateW$(n)\" distr=\"@weightsPrior\"/> </plate>","title":"7) Likelihood and priors"},{"location":"tutorials/#8-operators-how-mcmc-moves","text":"Operators propose new parameter values so MCMC can explore the posterior. BELLA examples use Bactrian random walks on weights: <plate var=\"n\" range=\"$(layersRange)\"> <operator spec=\"BactrianRandomWalkOperator\" parameter=\"@birthRateW$(n)\" weight=\"30.0\"/> <operator spec=\"BactrianRandomWalkOperator\" parameter=\"@deathRateW$(n)\" weight=\"30.0\"/> </plate> Use higher weights for parameters that need more frequent updates. Tune operator weights and step sizes if mixing is poor.","title":"8) Operators (how MCMC moves)"},{"location":"tutorials/#9-logging-including-bella-internals","text":"Logging controls what you see in output files. You can log: posterior, likelihood, prior skyline rates BELLA outputs BELLA network weights Example logger: <logger spec=\"Logger\" fileName=\"FBD.log\" logEvery=\"$(logEvery)\" model=\"@posterior\"> <log idref=\"posterior\"/> <log idref=\"prior\"/> <log idref=\"likelihood\"/> <log idref=\"birthRateSP\"/> <log idref=\"deathRateSP\"/> <log idref=\"birthRate\"/> <log idref=\"deathRate\"/> </logger> How BELLA logs its weights: bella.BayesMLP implements Loggable . On init, it prints headers like W.LayerX[i][j] for every weight matrix entry. X is the layer index (1-based). i is the input neuron index (including the bias row as index 0). j is the output neuron index. During logging, it prints every weight value in order. So if you add <log idref=\"birthRate\"/> and <log idref=\"deathRate\"/> , you will get the full network weights per MCMC sample in your log file.","title":"9) Logging (including BELLA internals)"},{"location":"tutorials/#10-json-df-substitutions","text":"BELLA examples use a data.json file that fills placeholders like $(treeFile) and $(nodes) at runtime. Run with: beast -DF path/to/data.json path/to/config.xml This is the easiest way to tweak a BELLA configuration without editing the XML directly. Next, choose a specific tutorial from the sidebar for a full, runnable example \ud83d\ude80.","title":"10) JSON + -DF substitutions"},{"location":"tutorials/fbd/","text":"Tutorial: FBD example This tutorial walks through the Fossilized Birth-Death (FBD) example in examples/FBD and shows how BELLA predicts skyline speciation and extinction rates. How BELLA fits into BEAST If you are new to BEAST, think of it this way: BEAST is a Bayesian engine that runs MCMC to estimate phylogenies and model parameters. BELLA is a package that provides a neural-network component ( bella.BayesMLP ) that BEAST can call inside the model. Your BEAST XML config file wires predictors -> BELLA network -> phylodynamic rates -> likelihood. In short: BELLA is a neural network node inside the BEAST model graph \ud83e\udde0\u27a1\ufe0f\ud83c\udf33. What you need to know before you start BELLA runs on BEAST 2.7+ and requires Java 17+ . You will work with BEAST XML configuration files . These files declare data, model components, priors, and MCMC settings. BELLA exposes a Bayesian MLP that is configured in the XML like any other BEAST component. Ready? Head to the installation guide next! \ud83d\ude80 Files you will use examples/FBD/config.xml - BEAST configuration with BELLA wired in. examples/FBD/data.json - values that fill the $(...) placeholders. examples/FBD/tree.nwk - fixed phylogenetic tree. examples/FBD/birth_rate_predictor.csv - predictor values for birth rate. Step 1: Review the JSON parameters Open examples/FBD/data.json and check these values: processLength : total time span of the FBD process. changeTimes : boundaries of skyline bins (space-separated). layersRange and nodes : define the MLP architecture. birthRatePredictorFile and deathRatePredictor : predictor inputs. birthRateLower/Upper , deathRateLower/Upper : bounds for rates. Important rule: the number of predictor values must equal length(changeTimes) + 1 . Step 2: See how BELLA is used in the XML Inside config.xml , BELLA is used twice - once for birth rates and once for death rates. Both are skyline parameters with the same time bins: <birthRate id=\"birthRateSP\" spec=\"SkylineVectorParameter\" changeTimes=\"$(changeTimes)\"> <skylineValues id=\"birthRate\" spec=\"bella.BayesMLP\" nodes=\"$(nodes)\"> <predictor spec=\"RealParameterFromXSV\" fileName=\"$(birthRatePredictorFile)\"/> <plate var=\"n\" range=\"$(layersRange)\"> <weights idref=\"birthRateW$(n)\"/> </plate> <outputActivation spec=\"bella.activations.Sigmoid\" lower=\"$(birthRateLower)\" upper=\"$(birthRateUpper)\"/> </skylineValues> </birthRate> The death-rate block is identical except the predictor is provided directly as a vector in data.json . Step 3: Run the analysis From the repository root: beast -DF FBD/data.json FBD/config.xml Step 4: Inspect outputs The example writes: FBD.log - posterior, likelihood, priors, sampling rate, and skyline rates. You can now plot skyline rates and interpret how BELLA mapped predictors to parameters \ud83c\udf89. Customizing for your own data Start by editing data.json first: adjust changeTimes to match your time bins replace the predictor file or predictor vector tune rate bounds and priors If you need more flexibility, edit config.xml directly. It contains inline comments that point to the main BELLA sections.","title":"FBD example"},{"location":"tutorials/fbd/#tutorial-fbd-example","text":"This tutorial walks through the Fossilized Birth-Death (FBD) example in examples/FBD and shows how BELLA predicts skyline speciation and extinction rates.","title":"Tutorial: FBD example"},{"location":"tutorials/fbd/#how-bella-fits-into-beast","text":"If you are new to BEAST, think of it this way: BEAST is a Bayesian engine that runs MCMC to estimate phylogenies and model parameters. BELLA is a package that provides a neural-network component ( bella.BayesMLP ) that BEAST can call inside the model. Your BEAST XML config file wires predictors -> BELLA network -> phylodynamic rates -> likelihood. In short: BELLA is a neural network node inside the BEAST model graph \ud83e\udde0\u27a1\ufe0f\ud83c\udf33.","title":"How BELLA fits into BEAST"},{"location":"tutorials/fbd/#what-you-need-to-know-before-you-start","text":"BELLA runs on BEAST 2.7+ and requires Java 17+ . You will work with BEAST XML configuration files . These files declare data, model components, priors, and MCMC settings. BELLA exposes a Bayesian MLP that is configured in the XML like any other BEAST component. Ready? Head to the installation guide next! \ud83d\ude80","title":"What you need to know before you start"},{"location":"tutorials/fbd/#files-you-will-use","text":"examples/FBD/config.xml - BEAST configuration with BELLA wired in. examples/FBD/data.json - values that fill the $(...) placeholders. examples/FBD/tree.nwk - fixed phylogenetic tree. examples/FBD/birth_rate_predictor.csv - predictor values for birth rate.","title":"Files you will use"},{"location":"tutorials/fbd/#step-1-review-the-json-parameters","text":"Open examples/FBD/data.json and check these values: processLength : total time span of the FBD process. changeTimes : boundaries of skyline bins (space-separated). layersRange and nodes : define the MLP architecture. birthRatePredictorFile and deathRatePredictor : predictor inputs. birthRateLower/Upper , deathRateLower/Upper : bounds for rates. Important rule: the number of predictor values must equal length(changeTimes) + 1 .","title":"Step 1: Review the JSON parameters"},{"location":"tutorials/fbd/#step-2-see-how-bella-is-used-in-the-xml","text":"Inside config.xml , BELLA is used twice - once for birth rates and once for death rates. Both are skyline parameters with the same time bins: <birthRate id=\"birthRateSP\" spec=\"SkylineVectorParameter\" changeTimes=\"$(changeTimes)\"> <skylineValues id=\"birthRate\" spec=\"bella.BayesMLP\" nodes=\"$(nodes)\"> <predictor spec=\"RealParameterFromXSV\" fileName=\"$(birthRatePredictorFile)\"/> <plate var=\"n\" range=\"$(layersRange)\"> <weights idref=\"birthRateW$(n)\"/> </plate> <outputActivation spec=\"bella.activations.Sigmoid\" lower=\"$(birthRateLower)\" upper=\"$(birthRateUpper)\"/> </skylineValues> </birthRate> The death-rate block is identical except the predictor is provided directly as a vector in data.json .","title":"Step 2: See how BELLA is used in the XML"},{"location":"tutorials/fbd/#step-3-run-the-analysis","text":"From the repository root: beast -DF FBD/data.json FBD/config.xml","title":"Step 3: Run the analysis"},{"location":"tutorials/fbd/#step-4-inspect-outputs","text":"The example writes: FBD.log - posterior, likelihood, priors, sampling rate, and skyline rates. You can now plot skyline rates and interpret how BELLA mapped predictors to parameters \ud83c\udf89.","title":"Step 4: Inspect outputs"},{"location":"tutorials/fbd/#customizing-for-your-own-data","text":"Start by editing data.json first: adjust changeTimes to match your time bins replace the predictor file or predictor vector tune rate bounds and priors If you need more flexibility, edit config.xml directly. It contains inline comments that point to the main BELLA sections.","title":"Customizing for your own data"}]}